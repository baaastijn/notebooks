{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating text with a pre-trained GPT2 in PyTorch\n",
    "\n",
    "This notebook was Adapted from this blog post : [Fine-tuning large Transformer models on a single GPU in PyTorch - Teaching GPT-2 a sense of humor](https://mf1024.github.io/2019/11/12/Fun-With-GPT-2/).\n",
    "\n",
    "In this notebook, I will use a pre-trained medium-sized GPT2 model from the [huggingface](https://github.com/huggingface/transformers) to generate some text.\n",
    "\n",
    "The easiest way to use huggingface transformer libraries is to install their pip package *transformers*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.1.0)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.48.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.1)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2020.7.14)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: six in ./.local/lib/python3.6/site-packages (from packaging->transformers) (1.15.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.6)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.48.2)\n",
      "Requirement already satisfied: six in ./.local/lib/python3.6/site-packages (from packaging->transformers) (1.15.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2020.7.14)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models and classes\n",
    "\n",
    "I use the [GPT2LMHeadModel](https://github.com/huggingface/transformers/blob/master/transformers/modeling_gpt2.py#L491) module for the language model, which is [GPT2Model](https://github.com/huggingface/transformers/blob/master/transformers/modeling_gpt2.py#L326), with an additional linear layer that uses input embedding layer weights to do the inverse operation of the embedding layer - to create logits vector for the dictionary from outputs of the GPT2.\n",
    "\n",
    "[GPT2Tokenizer](https://github.com/huggingface/transformers/blob/master/transformers/tokenization_gpt2.py#L106) is a byte-code pair encoder that will transform input text input into input tokens that the huggingface transformers were trained on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2-medium')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to first select topN tokens from the probability list and then based on the selected N word distribution\n",
    "# get random token ID\n",
    "def choose_from_top(probs, n=5):\n",
    "    ind = np.argpartition(probs, -n)[-n:]\n",
    "    top_prob = probs[ind]\n",
    "    top_prob = top_prob / np.sum(top_prob) # Normalize\n",
    "    choice = np.random.choice(n, 1, p = top_prob)\n",
    "    token_id = ind[choice][0]\n",
    "    return int(token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text generation\n",
    "\n",
    "At each prediction step, GPT2 model needs to know all of the previous sequence elements to predict the next one. Below is a function that will tokenize the starting input text, and then in a loop, one new token is predicted at each step and is added to the sequence, which will be fed into the model in the next step. In the end, the token list is decoded back into a text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_some_text(input_str, text_len = 250):\n",
    "\n",
    "    cur_ids = torch.tensor(tokenizer.encode(input_str)).unsqueeze(0).long().to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i in range(text_len):\n",
    "            outputs = model(cur_ids, labels=cur_ids)\n",
    "            loss, logits = outputs[:2]\n",
    "            softmax_logits = torch.softmax(logits[0,-1], dim=0) #Take the first(only one) batch and the last predicted embedding\n",
    "            next_token_id = choose_from_top(softmax_logits.to('cpu').numpy(), n=10) #Randomly(from the given probability distribution) choose the next word from the top n words\n",
    "            cur_ids = torch.cat([cur_ids, torch.ones((1,1)).long().to(device) * next_token_id], dim = 1) # Add the last word\n",
    "\n",
    "        output_list = list(cur_ids.squeeze().to('cpu').numpy())\n",
    "        output_text = tokenizer.decode(output_list)\n",
    "        print(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the text\n",
    "\n",
    "I will give thre different sentence beginnings to the GPT2 and let it generate the rest:\n",
    "\n",
    "\n",
    "***1. The Matrix is everywhere. It is all around us. Even now, in this very room. You can see it when you look out your window or when you turn on your television. You can feel it when you go to work… when you go to church… when you pay your taxes. It is the world that has been pulled over your eyes to blind you from the truth…***\n",
    "\n",
    "***2. Artificial general intelligence is…***\n",
    "\n",
    "***3. The Godfather: “I’m going to make him an offer he can’t refuse.”…***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Matrix is everywhere. It is all around us. Even now, in this very room. You can see it when you look out your window or when you turn on your television. You can feel it when you go to work... when you go to church... when you pay your taxes. It is the world that has been pulled over your eyes to blind you from the truth. _____________________ \"What is the truth? What is the world? You cannot understand it until you've experienced it.\" ~ Albert Einstein\n",
      "\n",
      "The Matrix is real. You can be sure of that. You don't need to be able to see the film, you just have to be aware of your surroundings. And if you can't be sure of anything, it's because you've never experienced it. _____________ \"We must be careful what we ask, but we cannot be sure of the answers. The answers are all around us and if we look, we will find them, they can be found, they may come and go as they please. We will never know them.\" ~ Albert Einstein\n",
      "\n",
      "The Matrix is real. You can be sure of that. You don't need to be able to see the film, you just have to be aware of your surroundings. And if you can't be sure of anything, it's because you've never experienced it. ~ _____________________\n",
      "\n",
      "You will find a way. The Matrix is real.\n",
      "\n",
      "You will find a way\n",
      "\n",
      "And you will never forget that way.\n",
      "\n",
      "It's the truth that you can't see, the truth\n",
      "\n",
      "That keeps you awake\n"
     ]
    }
   ],
   "source": [
    "generate_some_text(\" The Matrix is everywhere. It is all around us. Even now, in this very room. You can see it when you look out your window or when you turn on your television. You can feel it when you go to work... when you go to church... when you pay your taxes. It is the world that has been pulled over your eyes to blind you from the truth. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If everytime i went to work, I took my bike instead of my car...\n",
      "\n",
      "If i had the opportunity to travel all over the world...\n",
      "\n",
      "If i could take every opportunity i got...\n",
      "\n",
      "It would be awesome, but not if it was just a way to get some money to live, eat, have fun!\n",
      "\n",
      "\n",
      "I don't know why I even care anymore. This shit just makes no sense at all.\n",
      "\n",
      "\n",
      "And if you think that's a good thing for your life, then fuck you. I have no clue how you could live without it. I don't care whether you're rich, poor, black, brown, white, Asian, or whatever. I'm not going to be around to see how you survive.\n",
      "\n",
      "\n",
      "I don't give a fuck if you're rich or poor because if you're rich your life is going to be better, but when it comes to the fact that you can't have enough money for your shit, then I don't care. You can go get a job, but I can't see your fucking job being worth shit when it's fucking boring. I'm not saying that you can't get a job. I'm saying that you can't have any money that you can live off.\n",
      "\n",
      "\n",
      "If you don't want to do\n"
     ]
    }
   ],
   "source": [
    "generate_some_text(\"If everytime i went to work, I took my bike instead of my car...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Godfather: \"I'm going to make him an offer he can't refuse.\"  The only reason I don't think he's going to accept the offer is because the offer was so much less than what he really wanted.  The offer was to kill the Godfather, which I think would make him a little more sympathetic to him.  It's possible the offer he accepted was something else. But I think we can't discount all of the things that are really going on in the film.  There's a scene between the Godfather and a mobster that is really interesting because it reveals what a bad actor the Mafia is.  There's also this scene where the Godfather gets arrested and there's a scene when they are driving home in a van after a night out that I think makes the Godfather look more human. The Godfather: \"...I've seen the best. I've seen the worst.\" It was the best. That's the thing with the Mafia, you don't see them in the same light as people you know.  The people they work with know the people they're dealing with.  But the people who are dealing with them know them better than anybody else and they see them as a lot worse than anybody else they know.  The way that\n"
     ]
    }
   ],
   "source": [
    "generate_some_text(\" The Godfather: \\\"I'm going to make him an offer he can't refuse.\\\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
